{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pipelines w/ Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install needed libraries\n",
    "#!pip3 install catboost\n",
    "#!pip3 install sklearn_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "#library to make dummy classification data\n",
    "from sklearn.datasets import make_classification\n",
    "#library to impute missing numerical data\n",
    "from sklearn.impute import SimpleImputer\n",
    "#library to reduce dimensions and speed up machine learning algorithm training\n",
    "from sklearn.decomposition import PCA\n",
    "#libraries for algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#roc and auc scoring \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#pipeline concatenates multiple processes to run sequentially (ex. preprocessing, modeling, evaluation)\n",
    "from sklearn.pipeline import Pipeline\n",
    "#for saving and loading pipelines\n",
    "from joblib import dump,load\n",
    "#scaling and categorical encoding\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "#library to map columns to transformations before passing them into models for training\n",
    "from sklearn_pandas import DataFrameMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['feat_5', 'feat_6', 'feat_7', 'feat_8']\n",
    "numerical_features = ['feat_1', 'feat_2', 'feat_3', 'feat_4']\n",
    "\n",
    "#make_classification creates normally distributed data with a std of 1\n",
    "X, y = make_classification(n_samples=10000, \n",
    "                           n_features=4, #numeric\n",
    "                           n_redundant=0, #no redudant features\n",
    "                           random_state=42, \n",
    "                           weights=[0.5]) #50/50 split of positive and negative values\n",
    "\n",
    "#add categorical columns\n",
    "for col in range(4):\n",
    "    num_classes = np.random.randint(2, 10) #each categorical column's number of classes is a random number between 2 and 10\n",
    "    cat_col = np.random.randint(num_classes, size=X.shape[0]).reshape(-1,1) #creates entire column of random values between 0 and the number of classes\n",
    "    X = np.hstack((X, cat_col)) #appends each categorical feature column to the dataset\n",
    "\n",
    "#to dataframe\n",
    "columns = [f'feat_{i+1}' for i in range(X.shape[1])]\n",
    "X = pd.DataFrame(X, columns=columns)\n",
    "y = pd.DataFrame(y, columns=['label'])\n",
    "\n",
    "#scale regressors, modify categoricals (shift the mean and std of values to reflect real dataset values)\n",
    "for col in numerical_features:\n",
    "    mean = np.random.randint(10, 1000)\n",
    "    std = np.random.randint(1, 100)\n",
    "    X[col] = X[col].apply(lambda x: mean + std * x).astype(int)\n",
    "\n",
    "#create string value categorical features\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].apply(lambda x: f'str_{x}' if np.isnan(x)==False else x)\n",
    "\n",
    "#create nans in dataset (30% for each feature)\n",
    "for col in categorical_features + numerical_features:\n",
    "    X[col] = X[col].sample(frac=0.7)\n",
    "\n",
    "#create final dataframe\n",
    "df = X.merge(y,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df['label']\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map transformations to columns\n",
    "cat = [([c], [SimpleImputer(strategy='constant', fill_value='UNK'),\n",
    "              OneHotEncoder()]) for c in categorical_features]\n",
    "num = [([n], [SimpleImputer(), StandardScaler()]) for n in numerical_features] #imputes the mean of the column to replace nans and scales the column\n",
    "mapper = DataFrameMapper(num + cat, df_out=True) #df_out=True returns a dataframe\n",
    "lr_classifier = LogisticRegression()\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('lr_classifier', lr_classifier)\n",
    "])\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('dt_classifier', dt_classifier)\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('rf_classifier', rf_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of pipelines\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance evaluation\n",
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}\n",
    "\n",
    "#fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the mapper to transform features\n",
    "preprocessed_X_test = mapper.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-transformed features transposed\n",
    "X_test[numerical_features + categorical_features].head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#post-transformed features transposed\n",
    "preprocessed_X_test.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to evaluate the auc\n",
    "def evaluation(pipeline, X, y):\n",
    "    y_predict_proba = pipeline.predict_proba(X)[:, 1]\n",
    "    return{\n",
    "        'auc': roc_auc_score(y, y_predict_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_proba = pipeline_lr.predict_proba(X)[:, 1]\n",
    "pred = pd.DataFrame(y_predict_proba)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auc scores for training values\n",
    "print(evaluation(pipeline_lr, X_train, y_train))\n",
    "print(evaluation(pipeline_dt, X_train, y_train))\n",
    "print(evaluation(pipeline_rf, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#auc scores for test values\n",
    "print(evaluation(pipeline_lr, X_test, y_test))\n",
    "print(evaluation(pipeline_dt, X_test, y_test))\n",
    "print(evaluation(pipeline_rf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R-squared of classifiers\n",
    "for i, model in enumerate (pipelines):\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i], model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best classifier\n",
    "for i, model in enumerate(pipelines):\n",
    "    best_accuracy=model.score(X_test,y_test)\n",
    "    best_pipeline=model\n",
    "    best_classifier=i\n",
    "print('Classifier with best accuracy: {}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the pipelines for loading in other notebooks\n",
    "dump(pipeline_lr, '../pipelines/pipeline_lr.joblib')\n",
    "dump(pipeline_dt, '../pipelines/pipeline_dt.joblib')\n",
    "dump(pipeline_rf, '../pipelines/pipeline_rf.joblib')\n",
    "\n",
    "#save the test dataframe of dummy data for later usage (if needed)\n",
    "test_df.to_csv('../pipelines/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a pipeline\n",
    "lr = load('../pipelines/pipeline_lr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the pipeline\n",
    "lr.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
